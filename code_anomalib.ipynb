{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b709628",
   "metadata": {},
   "source": [
    "# Anomaly Detection using Anomalib library \n",
    "\n",
    "## PatchCore Alogrithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a22dffb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# pip install --upgrade --force-reinstall pip==24.0\n",
    "# pip install -r requirements.txt\n",
    "# pip install anomalib==1.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5912ba3b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip --version\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5968aae",
   "metadata": {},
   "source": [
    " ### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fed3eba",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from anomalib.data.utils import ValSplitMode\n",
    "from anomalib.deploy import ExportType\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from anomalib.models import Patchcore, Padim, EfficientAd\n",
    "from anomalib import TaskType\n",
    "from anomalib.data.image.folder import Folder\n",
    "from anomalib.loggers import AnomalibWandbLogger\n",
    "from anomalib.engine import Engine\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.transforms.v2.functional import to_pil_image\n",
    "import os\n",
    "\n",
    "transforms = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673ddb3a",
   "metadata": {},
   "source": [
    " ### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbc83eb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dataset_root = \"MVTecAD\"\n",
    "print(f\"Dataset root: {dataset_root}\")\n",
    "name = 'MVTecAD-hazelnut'\n",
    "patience = 3\n",
    "\n",
    "datamodule = Folder(\n",
    "    name=name,\n",
    "    root=dataset_root,\n",
    "    normal_dir=\"normal\",\n",
    "    abnormal_dir=\"abnormal\",\n",
    "    normal_test_dir=\"normal-test\",\n",
    "    num_workers=4,\n",
    "    task=TaskType.CLASSIFICATION,\n",
    "    seed=42,\n",
    "    # test_split_ratio=0.2,\n",
    "    val_split_mode=ValSplitMode.FROM_TEST, # default value\n",
    "    val_split_ratio=0.5, # default value\n",
    "    train_transform=transforms\n",
    ")\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ce9baf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Train images\n",
    "i, data = next(enumerate(datamodule.train_dataloader()))\n",
    "print(data.keys(), data[\"image\"].shape)\n",
    "\n",
    "for i, data in enumerate(datamodule.train_dataloader()):\n",
    "    print(i, len(data[\"image_path\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e039382d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "for i, data in enumerate(datamodule.test_dataloader()):\n",
    "    \n",
    "    print(i, len(data[\"image_path\"]))\n",
    "    # for i in range(len(data[\"image_path\"])):\n",
    "    #     print(data[\"image_path\"][i][39:], '-', data[\"label\"][i], data[\"image\"][i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a432f55",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# from the datamodule extract the train, val and test Pandas dataset and collect all the info in a csv\n",
    "train_dataset = datamodule.train_data.samples\n",
    "test_dataset = datamodule.test_data.samples\n",
    "val_dataset = datamodule.val_data.samples\n",
    "\n",
    "# check the data distribution for each category in each data split\n",
    "print(\"TRAIN DATASET FEATURES\")\n",
    "print(train_dataset.info())\n",
    "print(\"\")\n",
    "print(\"IMAGE DISTRIBUTION BY CLASS\")\n",
    "# print(\"\")\n",
    "desc_grouped = train_dataset[['label']].value_counts()\n",
    "print(desc_grouped)\n",
    "print('\\n')\n",
    "print(\"----------------------------------------------------------\")\n",
    "print(\"TEST DATASET FEATURES\")\n",
    "print(test_dataset.info())\n",
    "print(\"\")\n",
    "print(\"IMAGE DISTRIBUTION BY CLASS\")\n",
    "# print(\"\")\n",
    "desc_grouped = test_dataset[['label']].value_counts()\n",
    "print(desc_grouped)\n",
    "print('\\n')\n",
    "print(\"----------------------------------------------------------\")\n",
    "print(\"VAL DATASET FEATURES\")\n",
    "print(val_dataset.info())\n",
    "print(\"\")\n",
    "print(\"IMAGE DISTRIBUTION BY CLASS\")\n",
    "print(\"\")\n",
    "desc_grouped = val_dataset[['label']].value_counts()\n",
    "print(desc_grouped)\n",
    "\n",
    "# datamodule.train_data.samples.to_csv(os.path.join(\"/kaggle/working/\", \"datamodule_train.csv\"), index=False)\n",
    "# datamodule.test_data.samples.to_csv(os.path.join(\"/kaggle/working/\", \"datamodule_test.csv\"), index=False)\n",
    "# datamodule.val_data.samples.to_csv(os.path.join(\"/kaggle/working/\", \"datamodule_val.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0eb93c",
   "metadata": {},
   "source": [
    " ### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd2ff2a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model = Patchcore(coreset_sampling_ratio=0.1, num_neighbors=9)\n",
    "# model = Padim()\n",
    "# model = EfficientAd()\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        mode=\"max\",\n",
    "        monitor=\"image_AUROC\",\n",
    "        save_last=True,\n",
    "        verbose=True,\n",
    "        auto_insert_metric_name=True,\n",
    "        every_n_epochs=1,\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "            monitor=\"image_AUROC\",\n",
    "            mode=\"max\",\n",
    "            patience=patience,\n",
    "        ),\n",
    "]\n",
    "\n",
    "\n",
    "engine = Engine(\n",
    "    # callbacks=callbacks,\n",
    "    # threshold='F1AdaptiveThreshold',\n",
    "    # image_metrics='AUROC',\n",
    "    # pixel_metrics=\"AUROC\",\n",
    "    accelerator=\"auto\",  # \\<\"cpu\", \"gpu\", \"tpu\", \"ipu\", \"hpu\", \"auto\">,\n",
    "    devices=1,\n",
    "    task=TaskType.CLASSIFICATION,\n",
    ")\n",
    "\n",
    "print(\"Fit...\")\n",
    "engine.fit(datamodule=datamodule, model=model)\n",
    "\n",
    "print(\"Test...\")\n",
    "engine.test(datamodule=datamodule, model=model)\n",
    "\n",
    "# Export in torch\n",
    "print(\"Export weights...\")\n",
    "path_export_weights = engine.export(export_type=ExportType.TORCH,\n",
    "                                    model=model)\n",
    "\n",
    "print(\"path_export_weights: \", path_export_weights)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
